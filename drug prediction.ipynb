{"cells":[{"cell_type":"markdown","metadata":{"id":"L7iHhnVoaxq7"},"source":["## Code Template\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTO_jiLNROhF"},"outputs":[],"source":["import tensorflow as tf\n","import os\n","import numpy as np\n","import random\n","\n","seed = 23791\n","#seed = 23511\n","\n","random.seed(seed)\n","tf.random.set_seed(seed)\n","np.random.seed(seed)\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'"]},{"cell_type":"markdown","metadata":{"id":"15tXYosu7VQT"},"source":["### Step 1: Read File"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7h1n-hWaxq_"},"outputs":[],"source":["def read_file(f):\n","    \"\"\"This function is used to read files that are tab-separated. \n","    The function will split each row into two parts: ID and data.\n","    Data is a list of either sentence or tag sequence that is splitted into a list by space. \n","    \"\"\"\n","    data = open(f,'r').readlines()[1:]\n","    row_id = [i.split('\\t')[0].strip() for i in data]\n","    data = [i.split('\\t')[1].strip().split(' ') for i in data]\n","    return row_id,data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dUgJRS_8axrB"},"outputs":[],"source":["row_id_text, texts = read_file('./data/REVIEW_TEXT.txt')\n","row_id_tags, tags = read_file('./data/REVIEW_LABELSEQ.txt')\n","\n","#texts = texts[:200]  # if you want to limit to the first 2\n","#tags = tags[:200]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZ9CruK6ROhH"},"outputs":[],"source":["print(len(row_id_tags))\n","print(sum(len(s) for s in texts))\n","print(sum(len(t) for t in tags))"]},{"cell_type":"markdown","metadata":{"id":"yTRhexQVaxrC"},"source":["### Step 2: Modify Input Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3kot_ewaxrC"},"outputs":[],"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","unique_words = list(set([j for i in texts for j in i]))\n","word2idx = {j:i+1 for i,j in enumerate(unique_words)}\n","word2idx[\"PAD\"] = 0\n","\n","unique_tags = list(set([j for i in tags for j in i]))\n","label2idx = {j:i for i,j in enumerate(unique_tags)}\n","idx2label = {j:i for i,j in label2idx.items()}\n","\n","input_length = 20  # set input length to 20  .  This is the value of the maxlen parameter for pad_sequences below\n","\n","X = [[word2idx[j] for j in i] for i in texts]\n","# Add padding to inputs and set the length of inputs to 20.\n","# Everything past 25 will be truncated, and padding tokens (\"PAD\") will be appended to inputs shorter than 20\n","X = pad_sequences(maxlen = input_length, sequences = X, padding = \"post\", value = word2idx[\"PAD\"])\n","y = [[label2idx[j] for j in i] for i in tags]\n","# Add padding labels (These are \"O\"s since they are outside entities).  This maxlen must be the same as for X above.\n","y = pad_sequences(maxlen = input_length, sequences = y, padding = \"post\", value = label2idx[\"O\"])\n","y = [to_categorical(i, num_classes = len(unique_tags)) for i in y]"]},{"cell_type":"markdown","metadata":{"id":"nlaxw3GbaxrD"},"source":["### Split Data into Training and Validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RqyhsOYsaxrE"},"outputs":[],"source":["X_train, X_validation, y_train, y_validation  = train_test_split(X, y, test_size = 0.2)\n","print(len(y_validation))"]},{"cell_type":"markdown","metadata":{"id":"agnEMg_uaxrE"},"source":["### Build am LSTM model\n","You can add as many layers as you want."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6WIBLBbRaxrF"},"outputs":[],"source":["from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.metrics import CategoricalCrossentropy\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=len(word2idx.keys()),output_dim=20,input_length=input_length))\n","model.add(Bidirectional(LSTM(units=50,return_sequences=True,dropout=0.2), merge_mode = 'concat'))\n","model.add(Dense(len(label2idx.keys()), activation=\"relu\"))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"gNwXaeVJaxrG"},"source":["### Step 5: Results of how the LSTM model performs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYm8-X5_axrG"},"outputs":[],"source":["#import numpy as np\n","history = model.fit(X_train,np.array(y_train),batch_size=16,epochs=1,validation_split=0.1)\n","\n","print(\"fit done\")\n","\n","y_pred = model.predict(X_validation)\n","y_pred = np.argmax(y_pred, axis=-1)\n","y_validation = np.argmax(y_validation, -1)\n","y_pred = [[idx2label[i] for i in row] for row in y_pred]\n","y_validation = [[idx2label[i] for i in row]\n","                  for row in y_validation]"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"dbcfc0ba8b68ea870c3f1de8ed81ce37","grade":true,"grade_id":"cell-fa41028e30994631","locked":true,"points":5,"schema_version":3,"solution":false,"task":false},"id":"AUqsitJZROhL"},"outputs":[],"source":["# Make sure to run all cells up to this point\n","# This is a test cell\n","assert(len(y_pred) == len(y_validation))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5U9YLp2SaxrH"},"outputs":[],"source":["from sklearn_crfsuite.metrics import flat_classification_report\n","\n","for i in range(len(y_validation)):\n","    y_pred[i] = y_pred[i][:len(y_validation[i])]\n","\n","report = flat_classification_report(y_pred=y_pred, y_true=y_validation, digits=7)\n","print(report)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sh_EpjprROhM"},"outputs":[],"source":["accuracy = # report accuracy (copy and paste accuracy number from the report above)"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"b9e8291d6b4fff7d36a827d5cf14334a","grade":true,"grade_id":"cell-3a442fd3f711b551","locked":true,"points":15,"schema_version":3,"solution":false,"task":false},"id":"7v_ZJYCCROhM"},"outputs":[],"source":["# Check reported accuracy"]},{"cell_type":"markdown","metadata":{"id":"2d9eDfrjROhM"},"source":["### Step 6: Now Tweak Parameters\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4b2P4QiVROhM"},"outputs":[],"source":["# Run this cell and\n","# See how we are cutting some sentences short\n","print(\"length of actual sentence:\", len(texts[132]))\n","print(\"length of used sentence:  \", len(X[132]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xuf6MIptROhN"},"outputs":[],"source":["# (Run this cell)\n","# But there are examples like this as well:\n","print(\"actual:      \", len(texts[113]))\n","print(\"fed to model:\", len(X[113]))\n","print(texts[113])\n","print(X[113])"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"d43ea659c6ed2da00e2bb99fd601fd6f","grade":false,"grade_id":"cell-6229ed893906d31c","locked":true,"schema_version":3,"solution":false,"task":false},"id":"7UJcNvAbROhO"},"outputs":[],"source":["#import numpy as np\n","from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.metrics import CategoricalCrossentropy\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn_crfsuite.metrics import flat_classification_report\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N744aOCsROhO"},"outputs":[],"source":["unique_words = list(set([j for i in texts for j in i]))\n","word2idx = {j:i+1 for i,j in enumerate(unique_words)}\n","word2idx[\"PAD\"] = 0\n","\n","unique_tags = list(set([j for i in tags for j in i]))\n","label2idx = {j:i for i,j in enumerate(unique_tags)}\n","idx2label = {j:i for i,j in label2idx.items()}\n","\n","input_length_2 = ### set input length here!\n","\n","X = [[word2idx[j] for j in i] for i in texts]\n","# Add padding inputs       ************\n","X = pad_sequences(maxlen = input_length_2, sequences = X, padding = \"post\", value = word2idx[\"PAD\"])\n","y = [[label2idx[j] for j in i] for i in tags]\n","# Add padding labels.      ************     This must have the same maxlen as for X above.\n","y = pad_sequences(maxlen = input_length_2, sequences = y, padding = \"post\", value = label2idx[\"O\"])\n","y = [to_categorical(i, num_classes = len(unique_tags)) for i in y]\n","\n","X_train, X_validation, y_train, y_validation  = train_test_split(X, y, test_size = 0.2)"]},{"cell_type":"markdown","metadata":{"id":"eFidOAfPROhO"},"source":["- Remember, this should also be the input_length parameter of the Embedding layer, hence using the same variable to set both.\n","- Run the above and below cell again each time you change the input_length variable to see updated results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8a9qxFMPROhP"},"outputs":[],"source":["model = Sequential()\n","model.add(Embedding(input_dim=len(word2idx.keys()),output_dim=20,input_length=input_length_2))\n","model.add(Bidirectional(LSTM(units=50,return_sequences=True,dropout=0.2), merge_mode = 'concat'))\n","model.add(Dense(len(label2idx.keys()), activation=\"relu\"))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","\n","\n","history = model.fit(X_train,np.array(y_train),batch_size=16,epochs=1,validation_split=0.1)\n","\n","print(\"fit done\")\n","\n","y_pred = model.predict(X_validation)\n","y_pred = np.argmax(y_pred, axis=-1)\n","y_validation = np.argmax(y_validation, -1)\n","y_pred = [[idx2label[i] for i in row] for row in y_pred]\n","y_validation = [[idx2label[i] for i in row]\n","                  for row in y_validation]\n","\n","\n","for i in range(len(y_validation)):\n","    y_pred[i] = y_pred[i][:len(y_validation[i])]\n","\n","report = flat_classification_report(y_pred=y_pred, y_true=y_validation, digits=7)\n","print(report)"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"6d06018c5cc8e4c6f05815fb8baf9ae2","grade":true,"grade_id":"cell-cace115c8ff6094d","locked":true,"points":40,"schema_version":3,"solution":false,"task":false},"id":"gmc65HUeROhP"},"outputs":[],"source":["# Test for setting input_length_2"]},{"cell_type":"markdown","metadata":{"id":"b8OnapesROhP"},"source":["### One final, simple way to improve performance a lot of the time will be adjusting the epochs.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8TVRIPUKROhQ"},"outputs":[],"source":["unique_words = list(set([j for i in texts for j in i]))\n","word2idx = {j:i+1 for i,j in enumerate(unique_words)}\n","word2idx[\"PAD\"] = 0\n","\n","unique_tags = list(set([j for i in tags for j in i]))\n","label2idx = {j:i for i,j in enumerate(unique_tags)}\n","idx2label = {j:i for i,j in label2idx.items()}\n","\n","\n","input_length_3 = #input_length_2  ### set input length.  You may uncomment  input_length_2  if you wish to use that!\n","\n","X = [[word2idx[j] for j in i] for i in texts]\n","# Add padding inputs       ************\n","X = pad_sequences(maxlen = input_length_3, sequences = X, padding = \"post\", value = word2idx[\"PAD\"])\n","y = [[label2idx[j] for j in i] for i in tags]\n","# Add padding labels.      ************     This must have the same maxlen as for X above.\n","y = pad_sequences(maxlen = input_length_3, sequences = y, padding = \"post\", value = label2idx[\"O\"])\n","y = [to_categorical(i, num_classes = len(unique_tags)) for i in y]\n","\n","X_train, X_validation, y_train, y_validation  = train_test_split(X, y, test_size = 0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-8DMPK08ROhQ"},"outputs":[],"source":["epochs = ### set your epochs here!!\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=len(word2idx.keys()),output_dim=20,input_length=input_length_3))\n","model.add(Bidirectional(LSTM(units=50,return_sequences=True,dropout=0.2), merge_mode = 'concat'))\n","model.add(Dense(len(label2idx.keys()), activation=\"relu\"))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","\n","\n","history = model.fit(X_train,np.array(y_train),batch_size=16,epochs=epochs,validation_split=0.1)\n","\n","print(\"fit done\")\n","\n","y_pred = model.predict(X_validation)\n","y_pred = np.argmax(y_pred, axis=-1)\n","y_validation = np.argmax(y_validation, -1)\n","y_pred = [[idx2label[i] for i in row] for row in y_pred]\n","y_validation = [[idx2label[i] for i in row]\n","                  for row in y_validation]\n","\n","\n","for i in range(len(y_validation)):\n","    y_pred[i] = y_pred[i][:len(y_validation[i])]\n","\n","report = flat_classification_report(y_pred=y_pred, y_true=y_validation, digits=7)\n","print(report)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9puWhNWFROhR"},"outputs":[],"source":["# REPORT YOUR FINAL ACCURACY HERE:\n","accuracy_final =    ### fill this in!"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}